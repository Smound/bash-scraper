# Grupparbete - möte [2020-10-29 Thu]

<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-refresh-toc -->
**Table of Contents**

- [Grupparbete - möte [2020-10-29 Thu]](#grupparbete---möte-2020-10-29-thu)
    - [Scrapern](#scrapern)
    - [Schema](#schema)
    - [Tills nästa möte](#tills-nästa-möte)
    - [Hur ska vi gå tillväga?](#hur-ska-vi-gå-tillväga)
    - [Länkar](#länkar)

<!-- markdown-toc end -->

## Scrapern
  Vi kommer att koda en webscraper i bash.

  Vi ska skrapa ner recept.
## Schema
  Vi har valt att träffas via Google meet/Zoom 2ggr i veckan,
  *torsdagar på eftermiddag* och *fredagar på förmiddag*.
## Tills nästa möte
  Vi ska komma med förslag tills nästa möte på vilka hemsidor vi
  skulle kunna skrapa.
## Hur ska vi gå tillväga?
  Vi kom överens om att arbeta så att hela gruppen hänger med samma
  takt. Vi kommer delvis gå igenom saker tillsammans under möten
  (t.ex. "hur använder man sig av sin webbläsare för att undersöka
  vilka tags/classes man vill skrapa på") och delvis på egentid
  (t.ex. vi jobbar på samma eller liknande _feature_ under veckan på
  varsin git branch och sedan går igenom de olika lösningar på möten).

  Målet är att börja enkelt och bygga på i mån av tid, så att hela
  tiden ha en fungerande scraper.

## Länkar
  Ecce nämnde [denna artikel](https://medium.com/@LiliSousa/web-scraping-with-bash-690e4ee7f98d) som visar lite hur man kan börja
  bygga en scraper med bash.

  Vi testade lite att undersöka [recept.se](https://recept.se/) som möjligt
  scrape-target, och hur man "tänker" när man ska skrapa info (ex. få
  en lista av kategorier, för varje kategori få en lista av länkar
  till recept, igenom alla sidor. För varje recept, få ner namnet,
  ingredienslista och instuktioner).
